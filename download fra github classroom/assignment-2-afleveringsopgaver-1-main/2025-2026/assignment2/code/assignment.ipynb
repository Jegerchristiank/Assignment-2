{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3855a5ca",
   "metadata": {},
   "source": [
    "# Radiology Data Quality Assessment Through the Five Facets Framework\n",
    "\n",
    "**Assignment Part II — Data Quality Analysis**\n",
    "\n",
    "In this assignment, you will:\n",
    "1. Learn about the **Five Facets of Data Quality Assessment** framework\n",
    "2. Explore a synthetic radiology event log with intentional quality issues\n",
    "3. Work within the context of three research questions (RQs)\n",
    "4. **Choose and run** DQ assessment methods from a provided toolkit\n",
    "5. Analyse results through the lens of the five facets\n",
    "6. Manually explore the data to identify additional quality dimensions\n",
    "7. Reflect on the limitations of automated assessment and event logs\n",
    "\n",
    "**Important notes:**\n",
    "- You will write ~20-25% code (basic exploration, running analyses, creating visualisations)\n",
    "- Focus is on **choosing appropriate methods**, **interpreting results**, and **critical analysis**\n",
    "- **All numbered \"Reflection Questions\" should be answered in your main report (Deliverable 7), not in this notebook**\n",
    "- There is no single \"correct\" set of methods — you must justify your choices\n",
    "- In-notebook analyses are brief; deeper reflections go in your report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d3b19",
   "metadata": {},
   "source": [
    "## Part 0: Understanding the Context\n",
    "\n",
    "### Three Research Questions (RQs) Guiding This Assignment\n",
    "\n",
    "Your DQ assessment will be contextualised by three hypothetical research questions:\n",
    "\n",
    "**RQ1: Workflow Efficiency & Bottlenecks**  \n",
    "*\"What are the average turnaround times for different stages of the radiology workflow, and where do delays occur?\"*\n",
    "- **Task context**: Performance monitoring for department management\n",
    "- **Human stakeholders**: Radiology managers, administrators\n",
    "\n",
    "**RQ2: Quality of Care & Critical Finding Communication**  \n",
    "*\"How consistently are critical radiological findings communicated to ordering clinicians, and within what timeframes?\"*\n",
    "- **Task context**: Patient safety monitoring and regulatory compliance\n",
    "- **Human stakeholders**: Radiologists, clinicians, patient safety officers\n",
    "\n",
    "**RQ3: AI-Based Triage System Development**  \n",
    "*\"Can we develop an automated triage system to prioritise cases by urgency and complexity, routing them to appropriate radiologists?\"*\n",
    "- **Task context**: Clinical decision support and workflow optimisation\n",
    "- **Human stakeholders**: Radiologists, AI developers, workflow coordinators\n",
    "\n",
    "As you assess data quality, consider: **Which RQ(s) would be affected by the quality issues you find?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f2266",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eedd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import re\n",
    "\n",
    "# Schema requirements (metadata)\n",
    "REQUIRED_COLUMNS = [\n",
    "    'case_id', 'accession_number', 'event_time', 'activity',\n",
    "    'fhir_resource', 'actor', 'role',\n",
    "]\n",
    "\n",
    "EXPECTED_ACTIVITIES = [\n",
    "    'Order placed', 'Order accepted', 'Patient selected from worklist',\n",
    "    'Image acquisition start', 'Image acquisition end', 'Images uploaded to PACS',\n",
    "    'Case selected', 'Preliminary report created', 'Report validated and approved',\n",
    "    'Report finalised', 'Report distributed', 'Critical communication',\n",
    "]\n",
    "\n",
    "LOG_FILE = 'radiology_event_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event_log(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load CSV and parse event_time as datetime.\n",
    "    \n",
    "    Hint: Use pd.read_csv() and pd.to_datetime()\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = load_event_log(LOG_FILE)\n",
    "print(f\"Loaded {len(df)} events across {df['case_id'].nunique()} cases\")\n",
    "print(f\"Time range: {df['event_time'].min()} to {df['event_time'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4f766",
   "metadata": {},
   "source": [
    "### 1.1 Initial Data Exploration\n",
    "\n",
    "Before running formal DQ assessments, explore the data manually. Look at data types, columns, distributions, etc. You can also have a look at the .csv file. This corresponds to the **Data Facet** — understanding what data you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore the data structure\n",
    "# Write code to answer these questions or write your own exploratory questions and code:\n",
    "\n",
    "# 1. What are the data types of each column?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 2. What are the unique values in key columns: 'activity', 'role', 'fhir_resource', 'modality'?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. Are there any obvious missing values (NaN, None)? Which columns?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 4. How many events per case on average? What's the distribution?\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 5. What is the time span covered by this log?\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c745f",
   "metadata": {},
   "source": [
    "\n",
    "**→ Reflection Question 1** (answer in your main report):  \n",
    "What kind of data is logged in the file? Assuming data quality is good, how can the data be used to answer the RQs? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcc82b",
   "metadata": {},
   "source": [
    "## Part 2: The DQ Assessment Toolkit\n",
    "\n",
    "Below are **pre-implemented** functions for assessing various DQ dimensions. \n",
    "\n",
    "**Your task**: \n",
    "1. Review all available methods\n",
    "2. **Choose 4-5 methods** to run (you don't need to run all of them)\n",
    "3. Consider which methods are most relevant to the RQs\n",
    "4. Run the methods and analyse results\n",
    "5. Justify your choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20973f81",
   "metadata": {},
   "source": [
    "### 2.1 Available DQ Assessment Methods\n",
    "\n",
    "#### **Method 1: Schema Validation**\n",
    "- **DQ Dimension**: Completeness (schema-level)\n",
    "- **Description**: Checks if required columns exist, if event_time is valid, if activities are known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b311908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_1_schema_validation(df: pd.DataFrame) -> Dict[str, bool]:\n",
    "    \"\"\"\n",
    "    Validate schema-level completeness.\n",
    "    Checks against schema requirements (metadata)\n",
    "    Reflects how the system enforces data structure\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'columns_present': all(col in df.columns for col in REQUIRED_COLUMNS),\n",
    "        'datetime_valid': df['event_time'].notna().all(),\n",
    "        'activities_known': df['activity'].isin(EXPECTED_ACTIVITIES).all()\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eabb5b",
   "metadata": {},
   "source": [
    "#### **Method 2: Completeness — Missing Values Analysis**\n",
    "- **DQ Dimension**: Completeness (attribute-level)\n",
    "- **Description**: Identifies missing values, including hidden placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee8376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_2_completeness_missing_values(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Assess completeness by identifying missing and hidden missing values.\n",
    "    Detects NaN, empty strings, and potential placeholders\n",
    "    Finds missing values may indicate collection process issues\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'missing_counts': df.isnull().sum().to_dict(),\n",
    "        'empty_strings': {col: (df[col] == '').sum() for col in df.select_dtypes(include='object').columns},\n",
    "        'potential_placeholders': {}\n",
    "    }\n",
    "    \n",
    "    # Check for common placeholder values\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        placeholders = df[col].isin(['N/A', 'n/a', 'NA', 'Unknown', 'UNKNOWN', '-', '--', '99', '-99']).sum()\n",
    "        if placeholders > 0:\n",
    "            results['potential_placeholders'][col] = placeholders\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab4754",
   "metadata": {},
   "source": [
    "#### **Method 3: Accuracy — ICD-11 Code Validation**\n",
    "- **DQ Dimension**: Accuracy (syntactic correctness)\n",
    "- **Description**: Validates ICD-11 code format and placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7c3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_3_accuracy_icd11_validation(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Validate ICD-11 codes for format and context accuracy.\n",
    "    Checks code format against ICD-11 standard (reference data)\n",
    "    Informs system's data entry validation\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'codes_in_wrong_activity': [],\n",
    "        'invalid_format_codes': [],\n",
    "        'free_text_in_code_field': []\n",
    "    }\n",
    "    \n",
    "    if 'icd11_code' not in df.columns:\n",
    "        return results\n",
    "    \n",
    "    # ICD-11 format: 2 uppercase letters + numbers + optional dot + numbers\n",
    "    icd11_pattern = re.compile(r'^[A-Z]{2}[0-9]+(\\.[0-9]+)?$')\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        code = row.get('icd11_code', '')\n",
    "        if pd.isna(code) or code == '':\n",
    "            continue\n",
    "            \n",
    "        # Check if code appears in wrong activity\n",
    "        if code and row['activity'] != 'Report finalised':\n",
    "            results['codes_in_wrong_activity'].append((row['case_id'], row['activity'], code))\n",
    "        \n",
    "        # Check format validity\n",
    "        if code and not icd11_pattern.match(str(code)):\n",
    "            # Distinguish between format errors and free text\n",
    "            if len(str(code).split()) > 1 or not any(c.isdigit() for c in str(code)):\n",
    "                results['free_text_in_code_field'].append((row['case_id'], code))\n",
    "            else:\n",
    "                results['invalid_format_codes'].append((row['case_id'], code))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa984d8",
   "metadata": {},
   "source": [
    "#### **Method 4: Representativity — Actors, Roles, and Workforce Equity**\n",
    "- **DQ Dimension**: Representativity\n",
    "- **Description**: Assesses whether all expected actors/roles are represented and whether workload is distributed equitably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a013521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_4_representativity_actors_equity(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Assess representativity of actors and roles in the log, including equity analysis.\n",
    "    \n",
    "    Analyses:\n",
    "    - Distribution of actor/role attributes \n",
    "    - Whether data represents expected workflow participants\n",
    "    - Different human roles have different patterns\n",
    "    - Workload distribution equity across staff\n",
    "    - Gender balance if available\n",
    "    - Role representation completeness\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'unique_actors': df['actor'].nunique(),\n",
    "        'unique_roles': df['role'].nunique(),\n",
    "        'actor_distribution': df['actor'].value_counts().to_dict(),\n",
    "        'role_distribution': df['role'].value_counts().to_dict(),\n",
    "        'activities_per_role': df.groupby('role')['activity'].unique().to_dict()\n",
    "    }\n",
    "    \n",
    "    # Workload equity analysis\n",
    "    cases_per_actor = df.groupby('actor')['case_id'].nunique()\n",
    "    if len(cases_per_actor) > 0:\n",
    "        results['workload_equity'] = {\n",
    "            'mean_cases_per_actor': cases_per_actor.mean(),\n",
    "            'std_cases_per_actor': cases_per_actor.std(),\n",
    "            'min_cases': cases_per_actor.min(),\n",
    "            'max_cases': cases_per_actor.max(),\n",
    "            'gini_coefficient': None  # Could calculate if needed for detailed equity analysis\n",
    "        }\n",
    "        \n",
    "        # Identify potential equity issues (extreme outliers)\n",
    "        q1 = cases_per_actor.quantile(0.25)\n",
    "        q3 = cases_per_actor.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        overloaded = cases_per_actor[cases_per_actor > q3 + 1.5 * iqr]\n",
    "        underloaded = cases_per_actor[cases_per_actor < q1 - 1.5 * iqr]\n",
    "        \n",
    "        results['workload_outliers'] = {\n",
    "            'overloaded_actors': overloaded.to_dict(),\n",
    "            'underloaded_actors': underloaded.to_dict()\n",
    "        }\n",
    "    \n",
    "    # Role completeness: Are all expected clinical roles present?\n",
    "    expected_roles = ['Radiographer', 'Radiologist', 'Resident', 'Clerk']  # Adjust based on context\n",
    "    present_roles = set(df['role'].dropna().unique())\n",
    "    results['role_completeness'] = {\n",
    "        'expected_roles': expected_roles,\n",
    "        'present_roles': list(present_roles),\n",
    "        'missing_roles': list(set(expected_roles) - present_roles)\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eebac7",
   "metadata": {},
   "source": [
    "#### **Method 5: Representativity — Case Mix by Modality**\n",
    "- **DQ Dimension**: Representativity\n",
    "- **Description**: Assesses whether different imaging modalities are adequately represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b5df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_5_representativity_modality(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Assess representativity of imaging modalities.\n",
    "    Distribution of modality values\n",
    "    Different modalities represent different case types/complexity and have different data requirements. E.g., mobile X-ray (DX) has to have a location note.\n",
    "    \"\"\"\n",
    "    # Get modality from upload events\n",
    "    upload_events = df[df['activity'] == 'Images uploaded to PACS'].copy()\n",
    "    \n",
    "    if 'modality' not in upload_events.columns:\n",
    "        return {'error': 'Modality column not found'}\n",
    "    \n",
    "    results = {\n",
    "        'total_cases': upload_events['case_id'].nunique(),\n",
    "        'modality_distribution': upload_events['modality'].value_counts().to_dict(),\n",
    "        'modality_percentages': (upload_events['modality'].value_counts(normalize=True) * 100).to_dict(),\n",
    "        'missing_modality': upload_events['modality'].isna().sum()\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d61cf6",
   "metadata": {},
   "source": [
    "#### **Method 6: Representativity — Case Characteristics, Equipment, and Patient Demographics**\n",
    "- **DQ Dimension**: Representativity\n",
    "- **Description**: Assesses representativity across case urgency, anatomical regions, patient demographics, and equipment usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac509acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_6_representativity_comprehensive(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Assess comprehensive representativity across multiple dimensions:\n",
    "    - Case urgency levels (routine, urgent, stat)\n",
    "    - Anatomical regions/body parts examined\n",
    "    - Time of day / shift patterns\n",
    "    - Equipment usage (if logged)\n",
    "    - Patient demographics (age groups, if available)\n",
    "    \n",
    "    This informs:\n",
    "    - Whether training data for AI (RQ3) represents all case types\n",
    "    - Whether performance metrics (RQ1) cover all scenarios\n",
    "    - Ethical considerations: are certain patient groups under-represented?\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Urgency/Priority analysis from notes or case attributes\n",
    "    if 'notes' in df.columns:\n",
    "        # Extract urgency markers\n",
    "        df_temp = df.copy()\n",
    "        df_temp['has_stat'] = df_temp['notes'].astype(str).str.contains('stat|STAT|urgent|URGENT', case=False, na=False)\n",
    "        df_temp['has_routine'] = df_temp['notes'].astype(str).str.contains('routine|ROUTINE', case=False, na=False)\n",
    "        \n",
    "        urgency_cases = df_temp.groupby('case_id').agg({\n",
    "            'has_stat': 'any',\n",
    "            'has_routine': 'any'\n",
    "        })\n",
    "        \n",
    "        results['urgency_distribution'] = {\n",
    "            'stat_urgent_cases': urgency_cases['has_stat'].sum(),\n",
    "            'routine_cases': urgency_cases['has_routine'].sum(),\n",
    "            'unspecified': len(urgency_cases) - urgency_cases['has_stat'].sum() - urgency_cases['has_routine'].sum(),\n",
    "            'total_cases': len(urgency_cases)\n",
    "        }\n",
    "    \n",
    "    # Anatomical region analysis (if body_part column exists)\n",
    "    if 'body_part' in df.columns:\n",
    "        body_part_dist = df[df['activity'] == 'Images uploaded to PACS']['body_part'].value_counts()\n",
    "        results['anatomical_distribution'] = body_part_dist.to_dict()\n",
    "        results['anatomical_coverage'] = {\n",
    "            'unique_body_parts': len(body_part_dist),\n",
    "            'missing_body_part': df[df['activity'] == 'Images uploaded to PACS']['body_part'].isna().sum()\n",
    "        }\n",
    "    \n",
    "    # Temporal representativity: Are all shifts/times of day represented?\n",
    "    df_temp = df.copy()\n",
    "    df_temp['hour'] = df_temp['event_time'].dt.hour\n",
    "    df_temp['shift'] = pd.cut(df_temp['hour'], bins=[0, 8, 16, 24], labels=['Night', 'Day', 'Evening'], include_lowest=True)\n",
    "    \n",
    "    shift_cases = df_temp.groupby('case_id')['shift'].first().value_counts()\n",
    "    results['temporal_distribution'] = {\n",
    "        'cases_by_shift': shift_cases.to_dict(),\n",
    "        'shift_balance': shift_cases.to_dict()\n",
    "    }\n",
    "    \n",
    "    # Equipment diversity (if station_name or device_id available)\n",
    "    if 'station_name' in df.columns:\n",
    "        equipment_usage = df[df['activity'].str.contains('acquisition', case=False, na=False)]['station_name'].value_counts()\n",
    "        results['equipment_usage'] = {\n",
    "            'unique_stations': len(equipment_usage),\n",
    "            'distribution': equipment_usage.to_dict(),\n",
    "            'concentration': equipment_usage.max() / equipment_usage.sum() if len(equipment_usage) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Patient demographics (if available - age, gender)\n",
    "    # Note: Often not in event logs due to privacy, but important for ethics analysis\n",
    "    if 'patient_age' in df.columns:\n",
    "        ages = df.groupby('case_id')['patient_age'].first().dropna()\n",
    "        results['age_distribution'] = {\n",
    "            'mean_age': ages.mean(),\n",
    "            'age_groups': pd.cut(ages, bins=[0, 18, 45, 65, 100], labels=['Pediatric', 'Adult', 'Middle-aged', 'Elderly']).value_counts().to_dict()\n",
    "        }\n",
    "    \n",
    "    # Ethical consideration: Data concentration\n",
    "\n",
    "    results['ethical_notes'] = {    \n",
    "\n",
    "        'comment': 'Check if certain patient groups, times, or case types are systematically under-represented. This affects fairness of AI systems and generalisability of performance metrics.'    \n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9869a5",
   "metadata": {},
   "source": [
    "#### **Method 7: Conformance Check — Temporal Sequence**\n",
    "- **DQ Dimension**: Consistency (workflow conformance)\n",
    "- **Description**: Verifies activities occur in expected order with plausible timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c922bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_7_conformance_temporal_sequence(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Temporal sequence conformance.\n",
    "\n",
    "    Full workflow temporal sequence with optional resident path:\n",
    "        Order placed < Order accepted < Patient selected from worklist < Image acquisition start \n",
    "        < Image acquisition end < Images uploaded to PACS < Case selected\n",
    "        < [Optional for resident cases: Preliminary report created < Report validated and approved]\n",
    "        < Report finalised < Report distributed\n",
    "\n",
    "    Timestamp ordering and values\n",
    "    Expected workflow sequence (fitness for clinical process)\n",
    "    Whether logging accurately captured event order\n",
    "    \n",
    "    This method specifically helps identify BATCH LOGGING issues:\n",
    "    - Multiple events at identical timestamps\n",
    "    - All events clustered within very short timeframe (e.g., < 1 minute for entire case)\n",
    "    - Events recorded at suspicious times (e.g., all at 17:00 - end of shift)\n",
    "    \"\"\"\n",
    "    required_sequence = [\n",
    "        'Order placed', 'Order accepted', 'Patient selected from worklist',\n",
    "        'Image acquisition start', 'Image acquisition end', 'Images uploaded to PACS',\n",
    "        'Case selected', 'Report finalised', 'Report distributed'\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for case_id, case_df in df.groupby('case_id'):\n",
    "        case_df = case_df.sort_values('event_time')\n",
    "        violations = []\n",
    "        \n",
    "        # Check all required activities exist\n",
    "        missing = set(required_sequence) - set(case_df['activity'].values)\n",
    "        if missing:\n",
    "            violations.append(f\"Missing activities: {', '.join(missing)}\")\n",
    "        \n",
    "        # Check sequence order\n",
    "        activity_times = {}\n",
    "        for activity in required_sequence:\n",
    "            rows = case_df[case_df['activity'] == activity]\n",
    "            if len(rows) > 0:\n",
    "                activity_times[activity] = rows['event_time'].iloc[0]\n",
    "        \n",
    "        for i in range(len(required_sequence) - 1):\n",
    "            curr = required_sequence[i]\n",
    "            next_act = required_sequence[i + 1]\n",
    "            if curr in activity_times and next_act in activity_times:\n",
    "                if activity_times[curr] >= activity_times[next_act]:\n",
    "                    violations.append(f\"VIOLATION: {curr} >= {next_act}\")\n",
    "        \n",
    "        # BATCH LOGGING DETECTION: Check for duplicate timestamps\n",
    "        duplicates = case_df[case_df.duplicated('event_time', keep=False)]\n",
    "        if len(duplicates) > 0:\n",
    "            unique_dup_times = duplicates['event_time'].nunique()\n",
    "            violations.append(f\"WARNING - BATCH LOGGING: {len(duplicates)} events share {unique_dup_times} timestamp(s)\")\n",
    "        \n",
    "        # BATCH LOGGING DETECTION: Check for suspiciously short case duration\n",
    "        if len(case_df) > 3:  # Only check if case has multiple events\n",
    "            case_duration = (case_df['event_time'].max() - case_df['event_time'].min()).total_seconds() / 60\n",
    "            if case_duration < 1:  # All events within 1 minute\n",
    "                violations.append(f\"WARNING - BATCH LOGGING: All {len(case_df)} events within {case_duration:.2f} minutes (likely batch entry)\")\n",
    "        \n",
    "        # BATCH LOGGING DETECTION: Check for end-of-shift logging pattern\n",
    "        event_hours = case_df['event_time'].dt.hour.unique()\n",
    "        event_minutes = case_df['event_time'].dt.minute.unique()\n",
    "        if len(event_hours) == 1 and event_hours[0] in [17, 18, 8, 9]:  # Shift change times\n",
    "            if len(event_minutes) <= 2:  # All events within 2 minute values\n",
    "                violations.append(f\"WARNING - BATCH LOGGING: All events at {event_hours[0]:02d}:xx (end-of-shift pattern)\")\n",
    "        \n",
    "        # Check for implausible gaps\n",
    "        if 'Image acquisition end' in activity_times and 'Images uploaded to PACS' in activity_times:\n",
    "            gap = (activity_times['Images uploaded to PACS'] - activity_times['Image acquisition end']).total_seconds() / 60\n",
    "            if gap > 120:  # More than 2 hours\n",
    "                violations.append(f\"WARNING: Suspicious gap between acquisition and upload: {gap:.0f} minutes\")\n",
    "        \n",
    "        results.append({\n",
    "            'case_id': case_id,\n",
    "            'c1_passed': len(violations) == 0,\n",
    "            'c1_violations': '; '.join(violations) if violations else 'None'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593a8cc",
   "metadata": {},
   "source": [
    "#### **Method 8: Conformance Check — Critical Finding Communication**\n",
    "- **DQ Dimension**: Timeliness (task-specific)\n",
    "- **Description**: Ensures critical findings are communicated within acceptable timeframe\n",
    "- **Important**: When using this method, you should specify the `threshold_minutes` parameter and reflect on your choice. The default of 15 minutes may not be appropriate for all contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625e6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_8_conformance_critical_communication(df: pd.DataFrame, threshold_minutes: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Critical findings should be communicated timely.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Event log dataframe\n",
    "    threshold_minutes : int, default=15\n",
    "        Maximum acceptable time (in minutes) between report finalisation and critical communication.\n",
    "\n",
    "        \n",
    "    Facet considerations:\n",
    "    - Clinical requirement for urgent communication \n",
    "    - Timestamp accuracy and 'notes' field parsing \n",
    "    - What humans consider \"critical\" and \"timely\"\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for case_id, case_df in df.groupby('case_id'):\n",
    "        # Check if case is marked as critical\n",
    "        is_critical = case_df['notes'].astype(str).str.contains('critical=true', case=False, na=False).any()\n",
    "        \n",
    "        if not is_critical:\n",
    "            results.append({\n",
    "                'case_id': case_id,\n",
    "                'c4_passed': True,\n",
    "                'c4_detail': 'Not a critical case'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        final_row = case_df[case_df['activity'] == 'Report finalised']\n",
    "        comm_row = case_df[case_df['activity'] == 'Critical communication']\n",
    "        \n",
    "        if len(final_row) == 0:\n",
    "            results.append({\n",
    "                'case_id': case_id,\n",
    "                'c4_passed': False,\n",
    "                'c4_detail': 'Critical case missing Report finalised'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        if len(comm_row) == 0:\n",
    "            results.append({\n",
    "                'case_id': case_id,\n",
    "                'c4_passed': False,\n",
    "                'c4_detail': 'Critical case missing Critical communication event'\n",
    "            })\n",
    "\n",
    "            continue\n",
    "        \n",
    "        final_time = final_row['event_time'].iloc[0]\n",
    "        comm_time = comm_row['event_time'].iloc[0]\n",
    "        gap_minutes = (comm_time - final_time).total_seconds() / 60\n",
    "        \n",
    "        passed = 0 <= gap_minutes <= threshold_minutes\n",
    "        results.append({\n",
    "            'case_id': case_id,\n",
    "            'c4_passed': passed,\n",
    "            'c4_detail': f\"Communication gap: {gap_minutes:.1f} minutes (threshold: {threshold_minutes})\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16877dc2",
   "metadata": {},
   "source": [
    "#### **Method 9: Conformance Check — Modality-Specific Attributes**\n",
    "- **DQ Dimension**: Accuracy (semantic correctness)\n",
    "- **Description**: Validates modality-specific data requirements based on DICOM standards and clinical protocols\n",
    "\n",
    "These requirements reflect clinical imaging protocols and PACS data quality standards.\n",
    "\n",
    "**Modality Requirements Explained:**\n",
    "\n",
    "- **DX (Digital Radiography - Portable/Mobile X-ray)**: Must include patient location (e.g., ward, ICU, emergency) because equipment moves to patient. Location is critical for logistics and dose tracking.\n",
    "- **MR (if implemented)**: Should include field strength, sequence type, contrast timing\n",
    "- **CR (Computed Radiography)**: Must have minimum series count (≥2 for AP/lateral views) and instance count (≥4 images) to ensure complete diagnostic study. Single-view imaging is typically inadequate for diagnosis.\n",
    "- **CT (if implemented)**: Should include slice thickness, contrast usage, reconstruction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84eb9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_9_conformance_modality_attributes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Modality-specific attribute requirements.\n",
    "    \n",
    "    Validates that each imaging modality has its required metadata attributes:\n",
    "    - DX (portable X-ray): location information required\n",
    "    - CR (computed radiography): minimum series/instance counts for complete study\n",
    "    \n",
    "    Facet considerations:\n",
    "    - Modality codes and required attributes (Data Facet)\n",
    "    - PACS system should enforce these requirements (System Facet)\n",
    "    - Different imaging tasks have different clinical data needs (Task Facet)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for case_id, case_df in df.groupby('case_id'):\n",
    "        upload_row = case_df[case_df['activity'] == 'Images uploaded to PACS']\n",
    "        \n",
    "        if len(upload_row) == 0:\n",
    "            results.append({\n",
    "                'case_id': case_id,\n",
    "                'passed': False,\n",
    "                'detail': 'No upload event found'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        upload_row = upload_row.iloc[0]\n",
    "        modality = upload_row.get('modality', '')\n",
    "        violations = []\n",
    "        \n",
    "        # DX (portable) must have location - critical for mobile equipment tracking\n",
    "        if modality == 'DX':\n",
    "            notes = str(upload_row.get('notes', ''))\n",
    "            if 'location' not in notes.lower():\n",
    "                violations.append('DX portable missing location information (required for mobile equipment)')\n",
    "        \n",
    "        # CR must have sufficient series/instances for complete diagnostic study\n",
    "        elif modality == 'CR':\n",
    "            series = upload_row.get('series_count', 0)\n",
    "            instances = upload_row.get('instance_count', 0)\n",
    "            if pd.isna(series) or series < 2:\n",
    "                violations.append(f'CR has insufficient series: {series} (expected >= 2 for AP/lateral views)')\n",
    "            if pd.isna(instances) or instances < 4:\n",
    "                violations.append(f'CR has insufficient instances: {instances} (expected >= 4 for complete study)')\n",
    "        \n",
    "        results.append({\n",
    "            'case_id': case_id,\n",
    "            'passed': len(violations) == 0,\n",
    "            'detail': '; '.join(violations) if violations else 'All modality requirements met'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076583e",
   "metadata": {},
   "source": [
    "#### **Method 10: Turnaround Time Calculation with Batch Logging Detection**\n",
    "- **DQ Dimension**: Accuracy\n",
    "- **Description**: Calculates key turnaround time metrics for workflow stages and flags cases with potential batch logging issues that may distort TAT calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1b29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_10_turnaround_times(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Calculate turnaround times for key workflow stages with SIMPLE batch logging detection.\n",
    "    \n",
    "    Turnaround times are critical performance metrics but are only\n",
    "    meaningful if timestamps are accurate. This method flags cases\n",
    "    where batch logging may have occurred, which would make TAT calculations unreliable.\n",
    "    \n",
    "    Returns both TAT statistics and data quality warnings about batch logging.\n",
    "    \"\"\"\n",
    "    tat_results = []\n",
    "    batch_logging_flags = []\n",
    "    \n",
    "    for case_id, case_df in df.groupby('case_id'):\n",
    "        case_df = case_df.sort_values('event_time')\n",
    "        times = {}\n",
    "        \n",
    "        for activity in ['Order placed', 'Image acquisition start', 'Images uploaded to PACS', \n",
    "                         'Case selected', 'Report finalised', 'Report distributed']:\n",
    "            rows = case_df[case_df['activity'] == activity]\n",
    "            if len(rows) > 0:\n",
    "                times[activity] = rows['event_time'].iloc[0]\n",
    "        \n",
    "        # Calculate TATs\n",
    "        tat = {'case_id': case_id}\n",
    "        \n",
    "        if 'Order placed' in times and 'Image acquisition start' in times:\n",
    "            tat['order_to_acquisition_minutes'] = (times['Image acquisition start'] - times['Order placed']).total_seconds() / 60\n",
    "        \n",
    "        if 'Images uploaded to PACS' in times and 'Report finalised' in times:\n",
    "            tat['upload_to_report_minutes'] = (times['Report finalised'] - times['Images uploaded to PACS']).total_seconds() / 60\n",
    "        \n",
    "        if 'Order placed' in times and 'Report distributed' in times:\n",
    "            tat['total_tat_minutes'] = (times['Report distributed'] - times['Order placed']).total_seconds() / 60\n",
    "        \n",
    "        # BATCH LOGGING DETECTION for this case\n",
    "        batch_warnings = []\n",
    "        \n",
    "        # Check 1: Multiple events at identical timestamps\n",
    "        dup_times = case_df[case_df.duplicated('event_time', keep=False)]\n",
    "        if len(dup_times) > 0:\n",
    "            batch_warnings.append(f\"Duplicate timestamps: {len(dup_times)} events\")\n",
    "        \n",
    "        # Check 2: Unrealistically short total case duration\n",
    "        if len(case_df) > 3:\n",
    "            case_duration_minutes = (case_df['event_time'].max() - case_df['event_time'].min()).total_seconds() / 60\n",
    "            if case_duration_minutes < 1:\n",
    "                batch_warnings.append(f\"All events within {case_duration_minutes:.2f} min\")\n",
    "            tat['case_duration_minutes'] = case_duration_minutes\n",
    "        \n",
    "        # Check 3: Suspiciously short TAT values (likely batch-logged)\n",
    "        if 'order_to_acquisition_minutes' in tat and tat['order_to_acquisition_minutes'] < 5:\n",
    "            batch_warnings.append(f\"Unrealistic order-to-acquisition: {tat['order_to_acquisition_minutes']:.1f} min\")\n",
    "        \n",
    "        tat['batch_logging_suspected'] = len(batch_warnings) > 0\n",
    "        tat['batch_warnings'] = '; '.join(batch_warnings) if batch_warnings else 'None'\n",
    "        \n",
    "        tat_results.append(tat)\n",
    "        \n",
    "        if len(batch_warnings) > 0:\n",
    "            batch_logging_flags.append(case_id)\n",
    "    \n",
    "    tat_df = pd.DataFrame(tat_results)\n",
    "    \n",
    "    # Filter out suspected batch-logged cases for cleaner statistics\n",
    "    clean_tat_df = tat_df[~tat_df['batch_logging_suspected']] if 'batch_logging_suspected' in tat_df else tat_df\n",
    "    \n",
    "    summary = {\n",
    "        'mean_order_to_acquisition': tat_df['order_to_acquisition_minutes'].mean() if 'order_to_acquisition_minutes' in tat_df else None,\n",
    "        'mean_upload_to_report': tat_df['upload_to_report_minutes'].mean() if 'upload_to_report_minutes' in tat_df else None,\n",
    "        'mean_total_tat': tat_df['total_tat_minutes'].mean() if 'total_tat_minutes' in tat_df else None,\n",
    "        \n",
    "        # Clean statistics (excluding suspected batch-logged cases)\n",
    "        'mean_order_to_acquisition_clean': clean_tat_df['order_to_acquisition_minutes'].mean() if 'order_to_acquisition_minutes' in clean_tat_df and len(clean_tat_df) > 0 else None,\n",
    "        'mean_upload_to_report_clean': clean_tat_df['upload_to_report_minutes'].mean() if 'upload_to_report_minutes' in clean_tat_df and len(clean_tat_df) > 0 else None,\n",
    "        'mean_total_tat_clean': clean_tat_df['total_tat_minutes'].mean() if 'total_tat_minutes' in clean_tat_df and len(clean_tat_df) > 0 else None,\n",
    "        \n",
    "        # Batch logging statistics\n",
    "        'total_cases': len(tat_df),\n",
    "        'batch_logging_suspected_count': len(batch_logging_flags),\n",
    "        'batch_logging_percentage': (len(batch_logging_flags) / len(tat_df) * 100) if len(tat_df) > 0 else 0,\n",
    "        'batch_logged_cases': batch_logging_flags,\n",
    "        \n",
    "        'detailed_data': tat_df,\n",
    "        'warning': 'TAT calculations may be unreliable for batch-logged cases. Consider using clean statistics or investigating batch-logged cases separately.'\n",
    "    }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d547fa",
   "metadata": {},
   "source": [
    "#### **Method 11: Workload Distribution Analysis**\n",
    "- **DQ Dimension**: Representativity & Consistency\n",
    "- **Description**: Analyses how work is distributed across staff roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80e67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_11_workload_distribution(df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyse workload distribution across roles and actors.\n",
    "    Requires accurate actor and role attribution\n",
    "    Different roles represent different human workers\n",
    "    Workload metrics are defined by organisational needs\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Cases per role\n",
    "    cases_per_role = df.groupby('role')['case_id'].nunique().to_dict()\n",
    "    results['cases_per_role'] = cases_per_role\n",
    "    \n",
    "    # Events per role\n",
    "    events_per_role = df['role'].value_counts().to_dict()\n",
    "    results['events_per_role'] = events_per_role\n",
    "    \n",
    "    # Cases per individual actor\n",
    "    cases_per_actor = df.groupby('actor')['case_id'].nunique().sort_values(ascending=False).to_dict()\n",
    "    results['cases_per_actor'] = cases_per_actor\n",
    "    \n",
    "    # Identify potential data quality issues\n",
    "    actor_counts = df.groupby('actor')['case_id'].nunique()\n",
    "    if len(actor_counts) > 0:\n",
    "        mean_cases = actor_counts.mean()\n",
    "        std_cases = actor_counts.std()\n",
    "        outliers = actor_counts[(actor_counts > mean_cases + 2*std_cases) | (actor_counts < mean_cases - 2*std_cases)]\n",
    "        results['workload_outliers'] = outliers.to_dict()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7fd31",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Method Selection and Justification\n",
    "\n",
    "### Task : From the methods above (Methods 1-11), choose 4-5 methods to run. \n",
    "\n",
    "Complete this table in your main report.\n",
    "\n",
    "| Method | DQ Dimension | Primary Facets | Relevant to RQ(s) | Why did you choose this? | Expected findings |\n",
    "|--------|--------------|----------------|-------------------|--------------------------|-------------------|\n",
    "| Example: Method 1 ||||||\n",
    "\n",
    "Why did you NOT choose the other methods? What trade-offs did you consider? How did the three research questions (RQs) influence your method selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a03b1",
   "metadata": {},
   "source": [
    "## Part 4: Running Your Chosen Methods\n",
    "\n",
    "Now run each of your chosen methods. For each method:\n",
    "1. Run the code\n",
    "2. Display key results\n",
    "\n",
    "**→ Reflection Question 3** (answer in your main report):  \n",
    "Provide detailed interpretation of results from each chosen method:\n",
    "- Include key results.\n",
    "- Describe and interpret the results. Did they work as expected? Did they reveal any surprising insights? Could they be improved?\n",
    "- Were your expectations correct?\n",
    "- Which facet(s) does this result primarily inform about?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your first chosen method\n",
    "# Example:\n",
    "# results_1 = method_1_schema_validation(df)\n",
    "# print(\"=== Method 1: Schema Validation ===\")\n",
    "# for check, passed in results_1.items():\n",
    "#     print(f\"  {check}: {'✓ PASS' if passed else '✗ FAIL'}\")\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your second chosen method\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ae2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your third chosen method\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadba169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your fourth chosen method\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b020a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your fifth chosen method (if applicable)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976ad06",
   "metadata": {},
   "source": [
    "## Part 5: Manual Exploration — Propose Your Own DQ Dimension\n",
    "\n",
    "Based on your exploration, identify a DQ concern NOT adequately covered by the provided methods.\n",
    "\n",
    "**Task**:\n",
    "1. Manually explore the data to identify a quality issue\n",
    "2. Name and define a DQ dimension that captures this issue\n",
    "3. Map it to the Five Facets framework\n",
    "4. Write code to demonstrate the issue\n",
    "5. Propose an assessment approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4849179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore the data to find an uncovered quality issue\n",
    "# Suggestions:\n",
    "# - Temporal patterns (e.g., clustered or unusually timed events)\n",
    "# - Activity duration distributions (implausibly short/long durations)\n",
    "# - Cross-case patterns (same error repeated across cases)\n",
    "# - Consistency of actor names (typos, variations like \"Dr. Smith\" vs \"Dr Smith\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f171e3",
   "metadata": {},
   "source": [
    "### 5.1 Your Proposed DQ Dimension\n",
    "\n",
    "**→ Reflection Question 4** (answer in your main report):  \n",
    "Expand on your proposed DQ dimension. \n",
    "- Define your dimension.\n",
    "- *What specific pattern or issue in the data motivated this dimension? Reference your exploration code above. Provide concrete examples.*\n",
    "- *Which research question(s) would be affected by this quality issue? How?*\n",
    "- Map the dimension relevancy in across the five facets\n",
    "\n",
    "**Facet Mapping**:\n",
    "\n",
    "| Facet | Involvement (++, +, -) | Justification |\n",
    "|-------|------------------------|---------------|\n",
    "| Data | | |\n",
    "| Source | | |\n",
    "| System | | |\n",
    "| Task | | |\n",
    "| Human | | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function demonstrating assessment of your proposed dimension\n",
    "# This doesn't need to be complete, but should show the core logic\n",
    "\n",
    "def my_custom_dq_method(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Assess [YOUR DIMENSION NAME].\n",
    "    \n",
    "    YOUR DESCRIPTION\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run your method\n",
    "# custom_results = my_custom_dq_method(df)\n",
    "# print(\"=== My Custom DQ Assessment ===\")\n",
    "# Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c00c90",
   "metadata": {},
   "source": [
    " ## Part 6: Per-Facet Data Quality Synthesis\n",
    "\n",
    "**→ Reflection Question 5** (answer in your main report):  \n",
    "For each of the five data quality facets, interpret the results you got when running selected methods and assess the quality of the dataset. You can use these questions as guidance,\n",
    "- What did your methods reveal about data quality at \\[a facet\\] level?\n",
    "- What are the main data quality issues?\n",
    "- What could be the consequences in regard to the RQs?\n",
    "\n",
    "**Then discuss:**\n",
    "a) Which facet was most challenging to assess with the available methods? Why?  \n",
    "b) How else could these data quality facets be assessed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3415ce9",
   "metadata": {},
   "source": [
    "## Part 7: Invisible Work — Comparing Log to Workflow Diagram\n",
    "\n",
    "The assignment document includes a workflow diagram showing the actual radiology process with informal communication (orange dashed lines).\n",
    "\n",
    "**Task**: Identify gaps between the event log and the workflow diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: List all unique activities in your event log\n",
    "print(\"=== Activities in Event Log ===\")\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Compare these with activities/interactions shown in the workflow diagram\n",
    "# Make notes on what's missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ddc88",
   "metadata": {},
   "source": [
    "### 7.1 Invisible Work Analysis\n",
    "\n",
    "Complete the table with at least **3 activities** from the workflow diagram that do NOT appear in the log:\n",
    "\n",
    "| Activity from Diagram | Why not logged? | Which facet explains this? | Consequences | How could it be captured? |\n",
    "|----------------------|-----------------|---------------------------|--------------|---------------------------|\n",
    "| | | | | |\n",
    "| | | | | |\n",
    "| | | | | |\n",
    "\n",
    "---\n",
    "\n",
    "**→ Reflection Question 6** (answer in your main report):  \n",
    "a) For each activity, explain why it might not be logged (technical, social, economic reasons)\n",
    "b) Reflect on how a process model built \\emph{only} from the event log would fail to capture these activities. What are the potential consequences for system design, in regard to each of the research questions?\n",
    "c) How does your Part I experience (interview vs. observation) parallel the gap between event log and workflow diagram?\n",
    "d) What does the gap between logged data and actual practice tell us about building healthcare IT systems from ``data-driven'' approaches alone?\n",
    "e) Propose one concrete change to the logging system that would capture currently invisible work. Draw on concepts from Chapter 9 (Formal and informal information systems) to discuss trade-offs: Why is complete logging difficult or even unwelcome in real-world settings? How could negative impacts be mitigated?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
